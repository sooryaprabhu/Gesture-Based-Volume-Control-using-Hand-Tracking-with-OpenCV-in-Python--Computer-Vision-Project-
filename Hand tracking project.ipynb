{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLRXx8ueUmle"
      },
      "outputs": [],
      "source": [
        "#Hand tracking project\n",
        "import cv2\n",
        "import mediapipe as mp #for hand detection\n",
        "import pyautogui # to set the system volume on macOS.\n",
        "import subprocess # for executing system commands\n",
        "\n",
        "x1 = y1 = x2 = y2 = 0\n",
        "\n",
        "# Open the webcam (use 0 for the default webcam)\n",
        "webcam = cv2.VideoCapture(0)\n",
        "\n",
        "# To capture our hands\n",
        "my_hands = mp.solutions.hands.Hands()\n",
        "#module contains functions that can be used to draw landmarks and connections on the detected hands in the webcam frames.\n",
        "#These functions are helpful for visualizing the results of the hand detection process.\n",
        "drawing_utils = mp.solutions.drawing_utils #This line imports the drawing_utils module from mediapipe.solutions and assigns it to the variable drawing_utils\n",
        "\n",
        "# Set the initial volume level\n",
        "current_volume = 50\n",
        "alpha = 0.2  # Smoothing factor for the exponential moving average\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the webcam\n",
        "    ret, image = webcam.read()\n",
        "    frame_height, frame_width, _ = image.shape\n",
        "\n",
        "    # We need to convert our image into RGB format\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the frame with Mediapipe Hands\n",
        "    output = my_hands.process(rgb_image)\n",
        "\n",
        "    # Collecting all hands from the variable output\n",
        "    if output.multi_hand_landmarks:\n",
        "        for hand_landmarks in output.multi_hand_landmarks:\n",
        "            drawing_utils.draw_landmarks(image, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
        "            # For collecting the landmarks\n",
        "            landmarks = hand_landmarks.landmark\n",
        "            # Collecting id\n",
        "            for id, landmark in enumerate(landmarks):\n",
        "                x = int(landmark.x * frame_width)\n",
        "                y = int(landmark.y * frame_height)\n",
        "                if id == 4:\n",
        "                    cv2.circle(image, (x, y), radius=8, color=(0, 255, 255), thickness=3)\n",
        "                    x1 = x\n",
        "                    y1 = y\n",
        "                if id == 8:\n",
        "                    cv2.circle(image, (x, y), radius=8, color=(0, 0, 255), thickness=3)\n",
        "                    x2 = x\n",
        "                    y2 = y\n",
        "                    distance = ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5\n",
        "                    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
        "\n",
        "                    # Adjust the volume based on hand distance\n",
        "                    if distance > 50:\n",
        "                        current_volume = int(alpha * distance + (1 - alpha) * current_volume)\n",
        "                        current_volume = min(100, current_volume)\n",
        "                    else:\n",
        "                        current_volume = int(alpha * distance + (1 - alpha) * current_volume)\n",
        "                        current_volume = max(0, current_volume)\n",
        "\n",
        "    # Show the current volume as a vertical bar on the webcam image\n",
        "    volume_bar_height = int((current_volume / 100) * frame_height)\n",
        "    cv2.rectangle(image, (frame_width - 50, frame_height), (frame_width - 30, frame_height - volume_bar_height),\n",
        "                  (0, 255, 0), -1)\n",
        "\n",
        "    # Display volume level text\n",
        "    cv2.putText(image, f\"Volume: {current_volume}\", (frame_width - 100, frame_height - 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "    # Show the frame in a window titled 'Webcam'\n",
        "    cv2.imshow('Webcam', image)\n",
        "\n",
        "    # Set the volume on macOS using AppleScript\n",
        "    volume_percent = int(current_volume)\n",
        "    subprocess.run(['osascript', '-e', f'set volume output volume {volume_percent}'])\n",
        "\n",
        "    # Check for the 'Esc' key (ASCII code 27) to exit the loop\n",
        "    if cv2.waitKey(1) == 27:\n",
        "        break\n",
        "\n",
        "# Release the webcam and close the window\n",
        "webcam.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}